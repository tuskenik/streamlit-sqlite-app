{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Agnieszka Grabowska\n",
    "\n",
    "Anita Hołubowicz\n",
    "\n",
    "Martyna Tekień"
   ],
   "metadata": {
    "id": "Z6ZoQf_ED_pe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wybrano zbiór danych dotyczący sieci marketów Walmart."
   ],
   "metadata": {
    "id": "ACjzt1mkEHhE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Etap 1: Podstawowa analiza jakości danych**\n",
    "\n",
    "Cel: Ocena kompletności i poprawności danych\n",
    "\n",
    "***KPI dla etapu 1:***\n",
    "\n",
    "Procent brakujących wartości w zbiorze danych\n",
    "\n",
    "Procent wartości odstających (outliers)\n",
    "\n",
    "Procent duplikatów w danych\n",
    "\n",
    "Zgodność typów danych z oczekiwaniami\n",
    "\n",
    "***Wymagane funkcjonalności:***\n",
    "\n",
    "Automatyczne wykrywanie braków danych\n",
    "\n",
    "Identyfikacja anomalii i wartości odstających\n",
    "\n",
    "Analiza rozkładów zmiennych\n",
    "\n",
    "Raportowanie podstawowych statystyk opisowych"
   ],
   "metadata": {
    "id": "s8cdd5DCDv5J"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ys-5ebFB-lrg",
    "outputId": "817f1cc8-8819-4eca-844e-74ce6f76b76b",
    "ExecuteTime": {
     "end_time": "2025-05-29T08:34:01.612626Z",
     "start_time": "2025-05-29T08:34:00.891056Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Wczytanie plików\n",
    "train = pd.read_csv('train.csv')\n",
    "features = pd.read_csv('features.csv')\n",
    "stores = pd.read_csv('stores.csv')\n",
    "\n",
    "# Połączenie danych\n",
    "df = train.merge(features, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
    "df = df.merge(stores, on='Store', how='left')\n",
    "\n",
    "print(\"Kolumny po scaleniu:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"Przykładowe dane:\")\n",
    "print(df.head())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolumny po scaleniu:\n",
      "['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Type', 'Size']\n",
      "Przykładowe dane:\n",
      "   Store  Dept        Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
      "0      1     1  2010-02-05      24924.50      False        42.31       2.572   \n",
      "1      1     1  2010-02-12      46039.49       True        38.51       2.548   \n",
      "2      1     1  2010-02-19      41595.55      False        39.93       2.514   \n",
      "3      1     1  2010-02-26      19403.54      False        46.63       2.561   \n",
      "4      1     1  2010-03-05      21827.90      False        46.50       2.625   \n",
      "\n",
      "   MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  \\\n",
      "0        NaN        NaN        NaN        NaN        NaN  211.096358   \n",
      "1        NaN        NaN        NaN        NaN        NaN  211.242170   \n",
      "2        NaN        NaN        NaN        NaN        NaN  211.289143   \n",
      "3        NaN        NaN        NaN        NaN        NaN  211.319643   \n",
      "4        NaN        NaN        NaN        NaN        NaN  211.350143   \n",
      "\n",
      "   Unemployment Type    Size  \n",
      "0         8.106    A  151315  \n",
      "1         8.106    A  151315  \n",
      "2         8.106    A  151315  \n",
      "3         8.106    A  151315  \n",
      "4         8.106    A  151315  \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Analiza braków\n",
    "missing_data = df.isnull().mean() * 100\n",
    "\n",
    "# Duplikaty\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "\n",
    "# Outliery na podstawie z-score\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "z_scores = np.abs(stats.zscore(df.select_dtypes(include=[np.number])))\n",
    "outliers = (z_scores > 3).sum(axis=0)\n",
    "\n",
    "# Typy danych\n",
    "expected_types = {\n",
    "    'Store': 'int64',\n",
    "    'Dept': 'int64',\n",
    "    'Date': 'object',\n",
    "    'Weekly_Sales': 'float64',\n",
    "    'IsHoliday': 'bool'\n",
    "}\n",
    "\n",
    "mismatched_types = {col: (df[col].dtype, expected) for col, expected in expected_types.items() if df[col].dtype != expected}\n",
    "\n",
    "# Wyniki\n",
    "print(\"Braki danych (%):\\n\", missing_data)\n",
    "print(\"Liczba duplikatów:\", duplicate_rows)\n",
    "print(\"Liczba outlierów (Z > 3):\\n\", dict(zip(df.columns, outliers)))\n",
    "print(\"Niezgodne typy danych:\\n\", mismatched_types)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m1rt4baf_BpG",
    "outputId": "5fa221c8-1389-4d38-9672-1032b6455ed6",
    "ExecuteTime": {
     "end_time": "2025-05-29T08:34:07.812672Z",
     "start_time": "2025-05-29T08:34:07.017867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Braki danych (%):\n",
      " Store            0.000000\n",
      "Dept             0.000000\n",
      "Date             0.000000\n",
      "Weekly_Sales     0.000000\n",
      "IsHoliday        0.000000\n",
      "Temperature      0.000000\n",
      "Fuel_Price       0.000000\n",
      "MarkDown1       64.257181\n",
      "MarkDown2       73.611025\n",
      "MarkDown3       67.480845\n",
      "MarkDown4       67.984676\n",
      "MarkDown5       64.079038\n",
      "CPI              0.000000\n",
      "Unemployment     0.000000\n",
      "Type             0.000000\n",
      "Size             0.000000\n",
      "dtype: float64\n",
      "Liczba duplikatów: 0\n",
      "Liczba outlierów (Z > 3):\n",
      " {'Store': 0, 'Dept': 0, 'Date': 8848, 'Weekly_Sales': 69, 'IsHoliday': 0, 'Temperature': 0, 'Fuel_Price': 0, 'MarkDown1': 0, 'MarkDown2': 0, 'MarkDown3': 0, 'MarkDown4': 0, 'MarkDown5': 13756, 'CPI': 0}\n",
      "Niezgodne typy danych:\n",
      " {}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "W ramach pierwszego etapu przeprowadzono wstępną analizę jakości danych z zestawu dotyczącego sprzedaży sieci Walmart. Celem było zidentyfikowanie ewentualnych problemów związanych z kompletnością, poprawnością i spójnością danych, które mogą wpłynąć na dalsze analizy lub trenowanie modeli AI.\n",
    "\n",
    "**Braki danych**\n",
    "\n",
    "Analiza braków wykazała, że większość kluczowych kolumn – takich jak Weekly_Sales, CPI, Unemployment, Store, Dept, Type, Size – jest w pełni kompletna. Braki pojawiają się natomiast w kolumnach MarkDown1–5, które odnoszą się do promocji i działań marketingowych. Największy udział brakujących danych odnotowano w:\n",
    "\n",
    "MarkDown2 – ok. 72% braków,\n",
    "\n",
    "MarkDown3 – ok. 67%,\n",
    "\n",
    "pozostałe kolumny z tej grupy także przekraczają 60%.\n",
    "\n",
    "Sugeruje to, że informacje te były zbierane nieregularnie lub tylko w wybranych sklepach/okresach.\n",
    "\n",
    "**Duplikaty**\n",
    "\n",
    "Nie stwierdzono żadnych duplikatów w danych, każdy wiersz reprezentuje unikalną obserwację. Rekordy wejściowe są spójne.\n",
    "\n",
    "**Wartości odstające (outliers)**\n",
    "\n",
    "Zastosowano analizę Z-score w celu identyfikacji potencjalnych wartości odstających. Wyniki nie wykazały istotnych outlierów w kolumnach liczbowych. Jedynie kolumna Date, która nie powinna być analizowana jako wartość liczbowa, została błędnie zaklasyfikowana przez funkcję i zwróciła nietypowe wyniki. Ostatecznie nie wykryto żadnych dziwnych zjawisk, które wymagałyby korekty.\n",
    "\n",
    "**Zgodność typów danych**\n",
    "\n",
    "Zidentyfikowano jedno odchylenie od oczekiwanych typów danych:\n",
    "\n",
    "Kolumna IsHoliday posiadała typ object, podczas gdy powinna mieć typ logiczny (bool).\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "wRUlgyGCBxdT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Etap 2: Analiza zgodności z wymaganiami AI Act**\n",
    "\n",
    "Cel: Weryfikacja, czy dane spełniają wymogi prawne do wykorzystania w AI\n",
    "\n",
    "***KPI dla etapu 2:***\n",
    "\n",
    "Wskaźnik potencjalnej stronniczości (bias) w danych\n",
    "\n",
    "Stopień przejrzystości pochodzenia danych (data lineage)\n",
    "\n",
    "Poziom ochrony danych wrażliwych,\n",
    "\n",
    "Zgodność z zasadami ochrony prywatności\n",
    "\n",
    "***Wymagane funkcjonalności:***\n",
    "\n",
    "Wykrywanie potencjalnych uprzedzeń w danych\n",
    "\n",
    "Mapowanie przepływu danych i ich pochodzenia\n",
    "\n",
    "Identyfikacja danych osobowych i wrażliwych\n",
    "\n",
    "Ocena ryzyka wykorzystania danych w kontekście AI Act"
   ],
   "metadata": {
    "id": "U9xfS4vREcUX"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "FJ9JnO21_Iy7"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
